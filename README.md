# Facial-EmotionRecognition-Using-CNN

This project implements a Convolutional Neural Network (CNN) to classify facial expressions into seven categories: **Angry**, **Disgust**, **Fear**, **Happy**, **Neutral**, **Sad**, and **Surprise**. It uses grayscale images and is capable of both batch image classification and real-time emotion detection using a webcam.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/        # Training images organized by class
â”‚   â””â”€â”€ test/         # Validation images organized by class
â”œâ”€â”€ haarcascade_frontalface_default.xml
â”œâ”€â”€ model_file_30epochs.h5         # Trained CNN model
â”œâ”€â”€ main.py                        # Model training and evaluation
â”œâ”€â”€ test.py                        # Real-time emotion detection via webcam
â”œâ”€â”€ testdata.py                    # Emotion prediction on static images
â”œâ”€â”€ Facial_Expression_Recognition_Report.pdf
â””â”€â”€ README.md
```

---

## ğŸš€ Features

- CNN-based model trained on 48x48 grayscale images
- Real-time emotion detection using OpenCV and webcam
- Evaluation metrics: accuracy, loss curves, classification report, confusion matrix
- Data augmentation for better generalization
- Exported model for easy deployment

---

## ğŸ§  Model Architecture

- 4 Conv2D layers with ReLU activation + MaxPooling
- Dropout regularization (10â€“20%)
- Fully connected Dense layer
- Output layer with 7-way softmax classification
- Optimizer: Adam | Loss: Categorical Crossentropy

---

## ğŸ“Š Evaluation

- Training Accuracy: ~85â€“90%
- Validation Accuracy: ~75â€“80%
- Common misclassifications: *Neutral vs. Sad*, *Surprise vs. Fear*
- Visualized confusion matrix and per-class metrics using `sklearn`

---

## ğŸ›  Installation & Usage

### 1. Clone the Repository
```bash
git clone https://github.com/kabirkohli123/Facial-EmotionRecognition-Using-CNN
.git
cd Facial-EmotionRecognition-Using-CNN
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Train the Model
```bash
python main.py
```

### 4. Run Real-time Emotion Detection
```bash
python test.py
```

### 5. Predict Emotion from Image
```bash
python testdata.py
```

---

## ğŸ“ Dataset

This project assumes the dataset is organized as follows:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Angry/
â”‚   â”œâ”€â”€ Disgust/
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ test/
    â”œâ”€â”€ Angry/
    â”œâ”€â”€ Disgust/
    â”œâ”€â”€ ...
```

Each folder should contain grayscale `.jpg` or `.png` images.

---

## ğŸ“„ Report

A detailed summary of the approach, findings, and challenges can be found in:
ğŸ“„ [`Facial_Expression_Recognition_Report.pdf`](./Facial_Expression_Recognition_Report.pdf)

---

## ğŸ¤” Future Improvements

- Use face alignment for better preprocessing
- Train deeper models like ResNet or EfficientNet
- Address class imbalance using weighted loss or oversampling
- Optimize for low-latency edge deployment

---

## ğŸ‘¨â€ğŸ’» Author

- **Your Name**  
  [GitHub](https://github.com/kabirkohli123) â€¢ [LinkedIn]([https://linkedin.com/in/your-link](https://www.linkedin.com/in/kabir-kohli-50965a259/))

